# ğŸ–ï¸ Sign Language Detection using MediaPipe and OpenCV

## Overview
A machine learning project for real-time sign language gesture recognition using **MediaPipe**, **OpenCV**, and **Scikit-learn**.  
The system detects hand landmarks, preprocesses data, trains a model, and predicts gestures live from the webcam feed.

---

## âœ¨ Features
- Real-time hand landmark detection using **MediaPipe Hands**
- Automatic data saving in `.csv` format for each gesture
- Model training using **Scikit-learn** (e.g., `RandomForestClassifier`)
- Live prediction display using **OpenCV**
- Easy to expand with custom gestures

---

## ğŸ“ Project Structure
signlanguage/
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ hand_detector.py # Handles hand detection using MediaPipe
â”‚ â””â”€â”€ preprocessing.py # Handles saving and preprocessing landmark data
â”‚
â”œâ”€â”€ data/ # Folder where collected CSV data is stored
â”‚ â”œâ”€â”€ A.csv
â”‚ â”œâ”€â”€ B.csv
â”‚ â””â”€â”€ ...
â”‚
â”œâ”€â”€ model/
â”‚ â””â”€â”€ sign_model.pkl # Trained model file
â”‚
â”œâ”€â”€ collect_data.py # For capturing hand landmark samples
â”œâ”€â”€ train_model.py # For training model on collected data
â”œâ”€â”€ predict_live.py # For live gesture recognition
â””â”€â”€ README.md # Project documentation
---

## âš™ï¸ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/signlanguage.git
cd signlanguage
2. Create a Virtual Environment
python -m venv venv
# On Windows
venv\Scripts\activate
# On Mac/Linux
source venv/bin/activate

3. Install Dependencies
pip install -r requirements.txt

ğŸ§¾ Example requirements.txt
opencv-python
mediapipe
numpy
scikit-learn
tensorflow

ğŸ“š Library Explanations

opencv-python â†’ Used for capturing webcam video and displaying frames.

mediapipe â†’ Detects and tracks hand landmarks in real-time.

numpy â†’ Handles numerical operations on landmark coordinates.

scikit-learn â†’ For model training and classification.

tensorflow â†’ (Optional) For deep learning-based models if you expand this project later.

ğŸš€ Usage
To collect data:
python collect_data.py

To train the model:
python train_model.py

To run live prediction:
python predict_live.py

ğŸ§  How It Works

The webcam captures your hand using OpenCV.

MediaPipe extracts 3D hand landmarks.

These landmarks are normalized and saved as CSV samples.

Scikit-learn model (like Random Forest) is trained on this data.

During live prediction, the trained model classifies gestures in real-time.

ğŸ’¡ Future Enhancements

Add more gestures for broader recognition.

Implement deep learning models using TensorFlow/Keras.

Create a GUI interface for user-friendly interaction.

ğŸ‘¨â€ğŸ’» Author

Aviraj Chhetri
B.Sc. Computer Science (Hons) | Salesian College, Siliguri
